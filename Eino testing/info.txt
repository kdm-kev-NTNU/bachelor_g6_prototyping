Ta inspirasjon fra Highchart mappen for å undersøke og testing LLM-as-judge for råd som et LLM kan gi
basert på et sett av regler som dette


2. Hvordan mappe punktene dine til en konkret judge-rubrikk

Dette er kjernen. Du må gjøre vurderingskriteriene eksplisitte og faste.

Fast vurderingsrubrikk (eksempel)

Dette er det judge-prompten får, og kun dette:

Kriterium	Beskrivelse	Score
Dataforankring	Refererer eksplisitt til presentert input-data	0–2
Intern konsistens	Ingen selvmotsigelser	0–2
Fakta vs antagelser	Skiller tydelig mellom observasjon og tolkning	0–2
Usikkerhet	Anerkjenner begrensninger i data/konklusjon	0–2
Rådgivende tone	Foreslår, ikke instruerer	0–2

➡️ Maks score: 10

Dette gjør to viktige ting metodisk:

LLM kan ikke finne på egne kriterier

Evalueringen er repeterbar

Judge-prompt (konseptuelt, ikke ordrett)

Du skal evaluere kvaliteten på et svar basert på en fast rubrikk.
Du skal ikke vurdere om rådet er faglig riktig.
Du skal kun vurdere struktur, tydelighet og sporbarhet.

Returner kun JSON på følgende format:

{
  "data_referencing": 0,
  "internal_consistency": 0,
  "fact_vs_assumption": 0,
  "uncertainty_acknowledgement": 0,
  "advisory_tone": 0,
  "total_score": 0,
  "comment": "Kort, nøytral forklaring"
}


Dette matcher alle metodiske kravene du listet.

Implementer 

dette
- lag en enkel ui og fiktiv energibruk for et bygning som bruker for mye energi enn det bør basert på "bygnignsdetaljer"
- lag en hybrid retreival strategi for å gi råd, enkel rag pipeline
- chroma som en vector database
- docling for å parse pdf-ene 
- og andre top tier moduller
- system prompten for output må inkludere sitering
- legg til en LLM-as-ajudge, som bare ser på strukturen av outputen ikke om det er faglig forsvarbar